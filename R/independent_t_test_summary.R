#' @title Multiverse of Independent Samples t-test Results (Summary Statistics)
#'
#' @description
#' This function explores the "multiverse" of possible Cohen's *d* effect sizes,
#' confidence intervals (CIs), and *p*-values that are compatible with a set
#' of reported summary statistics (Means, SDs, Ns).
#'
#' The multiverse is generated by varying:
#' \itemize{
#'   \item Input Rounding: Adjusting reported statistics by +/- half of the
#'         last decimal place (ULP - Unit in the Last Place), as specified by
#'         \code{m_digits} and \code{sd_digits}. This implicitly allows any
#'         rounding rule whose result lies within this interval (from truncation
#'         toward negative infinity up to truncation toward positive infinity);
#'         the rounding mechanism for the input M and SD cannot be restricted
#'         to a single specific rule.
#'   \item Effect Size Type: Using both Cohen's *d* and Hedges' *g*.
#'   \item CI Methods: Wald-type CIs (using *t* distributions with pooled or
#'         Welch variance) and the Noncentral *t* (NCT) distribution.
#'   \item P-value Methods: Using *t*-tests (Student's pooled or Welch's
#'         unpooled).
#'   \item Output Rounding: Applying different rounding methods ("half_up",
#'         "half_down", "bankers", "trunc") to the final *d*/CI and *p*-value
#'         (governed by the \code{output_rounding} argument).
#'   \item Direction: The calculation uses the direction implied by the order of
#'         the supplied means (M1 - M2) or its reverse, depending on
#'         \code{direction}.
#'   \item SD vs. SE Interpretation (optional): If
#'         \code{include_se_sd_confusion = TRUE}, the function also includes
#'         a branch where reported SDs are interpreted as standard errors and
#'         converted to SDs via \eqn{SD = SE \times \sqrt{n}} before computing
#'         *d*, CIs, and *p*-values.
#' }
#'
#' @param m1 Numeric. Mean of Group 1.
#' @param m2 Numeric. Mean of Group 2.
#' @param sd1 Numeric. Standard deviation of Group 1 (assumed sample SD by default).
#' @param sd2 Numeric. Standard deviation of Group 2 (assumed sample SD by default).
#' @param n1 Numeric. Sample size of Group 1.
#' @param n2 Numeric. Sample size of Group 2.
#' @param m_digits Integer. Number of decimal places to assume for the reported
#'   means (\code{m1}, \code{m2}) when constructing the +/- 0.5 ULP adjustment
#'   grid. This controls the width of the interval within which the unrounded
#'   mean is assumed to lie. If \code{NULL}, no adjustment grid is generated
#'   for the means (i.e., the reported means are treated as exact).
#' @param sd_digits Integer. Number of decimal places to assume for the reported
#'   SDs (\code{sd1}, \code{sd2}) when constructing the +/- 0.5 ULP adjustment
#'   grid. This controls the width of the interval within which the unrounded
#'   SD is assumed to lie. If \code{NULL}, no adjustment grid is generated for
#'   the SDs (i.e., the reported SDs are treated as exact).
#'   Note that specifying \code{m_digits} and \code{sd_digits} defines only the
#'   size of the rounding unit; the actual rounding rule for the original
#'   reporting (e.g., round half up vs truncate) is not constrained and is
#'   implicitly allowed to be anything whose outputs fall within the +/- 0.5 ULP
#'   interval.
#' @param d Numeric. Reported Cohen's *d* or Hedges' *g* estimate.
#' @param d_ci_lower Numeric. Reported lower bound of the CI for *d*.
#' @param d_ci_upper Numeric. Reported upper bound of the CI for *d*.
#' @param d_digits Integer. Number of decimal places to which *d* and its CI
#'   bounds were reported. Must be supplied if \code{d} is non-\code{NULL}.
#' @param p Numeric. Reported p-value.
#' @param p_digits Integer. Number of decimal places to which the p-value was
#'   reported. Must be supplied if \code{p} is non-\code{NULL}.
#' @param alpha Numeric. Significance level for CIs (default is 0.05).
#' @param ci_methods Character vector. CI methods to include.
#'   Allowed: \code{"wald_t"}, \code{"welch_t"}, \code{"nct"}.
#'   If \code{NULL}, all are used.
#' @param p_methods Character vector. P-value methods to include.
#'   Allowed: \code{"student_t"}, \code{"welch_t"}.
#'   If \code{NULL}, both are used.
#' @param output_rounding Character vector. Rounding methods applied to both
#'   effect sizes (*d*/*g* and CIs) and p-values.
#'   Allowed: \code{"half_up"}, \code{"half_down"}, \code{"bankers"}, \code{"trunc"}.
#'   If \code{NULL}, all are used.
#' @param direction Character. Whether to compute the effect as M1 - M2,
#'   M2 - M1, or both. One of \code{"m1_minus_m2"}, \code{"m2_minus_m1"},
#'   \code{"both"}.
#' @param include_se_sd_confusion Logical. If \code{TRUE}, the multiverse also
#'   includes a branch that interprets \code{sd1} and \code{sd2} as standard
#'   errors and converts them to SDs via \eqn{SD = SE \times \sqrt{n}} before
#'   computing effect sizes, CIs, and p-values. Default is \code{FALSE}.
#'
#' @return A list with three elements:
#' \itemize{
#'   \item \code{reproduced}: Data frame summarising whether the reported *d*
#'         and *p* fall within the ranges generated by the multiverse.
#'   \item \code{d_results}: Data frame detailing all calculated effect sizes and
#'         CIs. Contains additional columns such as \code{sd_interpretation},
#'         indicating whether SDs were used as reported (\code{"sd"}) or derived
#'         from SE (\code{"se_converted"}), and \code{d_rounded},
#'         \code{ci_lower_rounded}, \code{ci_upper_rounded} for each combination
#'         of analytic choices and output rounding.
#'   \item \code{p_results}: Data frame detailing all calculated p-values.
#'         Includes \code{sd_interpretation}, \code{p_unrounded},
#'         \code{p_rounded}, and indicators of whether the rounded p-value
#'         matches the reported one under each rounding rule.
#' }
#'
#' @importFrom roundwork round_up round_down round_trunc
#' @importFrom stats pt qt uniroot pnorm qnorm
#' @importFrom dplyr summarise mutate arrange bind_cols select between
#' @importFrom tibble as_tibble rownames_to_column
#' @importFrom scales breaks_pretty
#'
#' @export
independent_t_test_summary <- function(
    m1 = NULL, 
    m2 = NULL, 
    sd1 = NULL, 
    sd2 = NULL,
    n1 = NULL, 
    n2 = NULL,
    m_digits = NULL,
    sd_digits = NULL,
    output_rounding = NULL,
    p = NULL, 
    p_digits = NULL,
    p_methods = NULL,
    alpha = 0.05,
    d = NULL, 
    d_ci_lower = NULL, 
    d_ci_upper = NULL,
    d_digits = NULL,
    direction = c("m1_minus_m2", "m2_minus_m1", "both"),
    ci_methods = NULL,
    include_se_sd_confusion = FALSE
) {
  
  direction <- match.arg(direction)
  
  # Coerce reported values
  d_num          <- if (!is.null(d)) as.numeric(d) else NA_real_
  d_ci_lower_num <- if (!is.null(d_ci_lower)) as.numeric(d_ci_lower) else NA_real_
  d_ci_upper_num <- if (!is.null(d_ci_upper)) as.numeric(d_ci_upper) else NA_real_
  p_num          <- if (!is.null(p)) as.numeric(p) else NA_real_
  
  
  # # --- Validation of m_digits and sd_digits (ULP for M and SD) ---------------
  # 
  # # Basic numeric checks 
  # if (!is.null(m_digits)) {
  #   if (!is.numeric(m_digits) || length(m_digits) != 1L ||
  #       !is.finite(m_digits) || m_digits < 0) {
  #     stop("'m_digits' must be a single non-negative finite number (e.g. 1 or 2).")
  #   }
  #   m_digits <- as.integer(m_digits)
  # }
  # 
  # if (!is.null(sd_digits)) {
  #   if (!is.numeric(sd_digits) || length(sd_digits) != 1L ||
  #       !is.finite(sd_digits) || sd_digits < 0) {
  #     stop("'sd_digits' must be a single non-negative finite number (e.g. 2).")
  #   }
  #   sd_digits <- as.integer(sd_digits)
  # }
  
  # --- Validation of m_digits and sd_digits (ULP for M and SD) ---------------
  # Literal precision of inputs as written (for diagnostics)
  obs_m_digits  <- max(.get_digits(m1),  .get_digits(m2))
  obs_sd_digits <- max(.get_digits(sd1), .get_digits(sd2))
  
  # Require m_digits
  if (is.null(m_digits)) {
    stop(
      "You must supply 'm_digits'. ",
      "Specify the number of decimal places the means (m1, m2) were reported to, ",
      "e.g. m_digits = 1 for 10.3 or m_digits = 2 for 10.30."
    )
  }
  # Require sd_digits
  if (is.null(sd_digits)) {
    stop(
      "You must supply 'sd_digits'. ",
      "Specify the number of decimal places the SDs (sd1, sd2) were reported to, ",
      "e.g. sd_digits = 2 for 3.10."
    )
  }
  
  # m_digits checks
  if (!is.numeric(m_digits) || length(m_digits) != 1L ||
      !is.finite(m_digits) || m_digits < 0) {
    stop("'m_digits' must be a single non-negative finite integer (e.g. 1 or 2).")
  }
  if (m_digits %% 1 != 0) {
    stop(
      "'m_digits' must be an integer number of decimal places (e.g. 1 or 2), not ",
      m_digits, "."
    )
  }
  m_digits <- as.integer(m_digits)
  
  if (m_digits < obs_m_digits) {
    stop(
      "m_digits = ", m_digits, " is smaller than the apparent decimal precision of m1/m2 (",
      obs_m_digits, "). This suggests that the means carry more decimal places than ",
      "your rounding grid assumes (often due to floating-point artefacts or prior ",
      "processing)."
    )
  }
  if (m_digits > obs_m_digits) {
    warning(
      "m_digits = ", m_digits, " is larger than the apparent precision of m1/m2 (",
      obs_m_digits, "). This assumes implied trailing zeros (e.g., stored 3.1 ",
      "representing a reported 3.10). Please verify that this matches the reporting."
    )
  }
  
  # sd_digits checks
  if (!is.numeric(sd_digits) || length(sd_digits) != 1L ||
      !is.finite(sd_digits) || sd_digits < 0) {
    stop("'sd_digits' must be a single non-negative finite integer (e.g. 2).")
  }
  if (sd_digits %% 1 != 0) {
    stop(
      "'sd_digits' must be an integer number of decimal places (e.g. 2), not ",
      sd_digits, "."
    )
  }
  sd_digits <- as.integer(sd_digits)
  
  if (sd_digits < obs_sd_digits) {
    stop(
      "sd_digits = ", sd_digits, " is smaller than the apparent decimal precision of sd1/sd2 (",
      obs_sd_digits, "). This suggests that the SDs carry more decimal places than ",
      "your rounding grid assumes (often due to floating-point artefacts)."
    )
  }
  if (sd_digits > obs_sd_digits) {
    warning(
      "sd_digits = ", sd_digits, " is larger than the apparent precision of sd1/sd2 (",
      obs_sd_digits, "). This assumes implied trailing zeros in the reported SDs ",
      "(e.g., 2.3 representing 2.30). Please verify that this matches the reporting."
    )
  }
  
  
  # If you report d, you must also tell us how many decimals it was rounded to
  if (!is.null(d) && is.null(d_digits)) {
    stop(
      "You supplied 'd' but not 'd_digits'. ",
      "Please provide the number of decimal places d was reported to, e.g. d_digits = 2."
    )
  }
  
  # If you report p, you must also tell us how many decimals it was rounded to
  if (!is.null(p) && is.null(p_digits)) {
    stop(
      "You supplied 'p' but not 'p_digits'. ",
      "Please provide the number of decimal places p was reported to, e.g. p_digits = 3."
    )
  }
  
  # Check that d_digits, if supplied, is a single non-negative integer
  if (!is.null(d_digits)) {
    if (!is.numeric(d_digits) || length(d_digits) != 1L || !is.finite(d_digits) || d_digits < 0) {
      stop("'d_digits' must be a single non-negative finite number (e.g. 2).")
    }
    d_digits <- as.integer(d_digits)
  } else {
    # No reported d: we still need some rounding for the multiverse output
    d_digits <- 2L
  }
  
  # Check that p_digits, if supplied, is a single non-negative integer
  if (!is.null(p_digits)) {
    if (!is.numeric(p_digits) || length(p_digits) != 1L || !is.finite(p_digits) || p_digits < 1) {
      stop("'p_digits' must be a single non-negative finite number greater than zero (e.g. 3).")
    }
    p_digits <- as.integer(p_digits)
  } else {
    # No reported p: we still need some rounding for the multiverse output
    p_digits <- 3L
  }
  
  params <- .multiverse_validate_and_setup_summary(
    ci_methods, p_methods, output_rounding,
    m1, m2, sd1, sd2, n1, n2
  )
  
  d_results <- list()
  p_results <- list()
  idx_d <- 1
  idx_p <- 1
  
  res_summary <- .multiverse_from_summary_stats(
    m1, m2, sd1, sd2, n1, n2,
    params$ci_methods, params$p_methods, params$output_rounding,
    d_digits, p_digits, m_digits, sd_digits, alpha, 
    d_num, d_ci_lower_num, d_ci_upper_num, p_num,
    idx_d, idx_p,
    direction = direction,
    include_se_sd_confusion = include_se_sd_confusion
  )
  d_results <- c(d_results, res_summary$d_results)
  p_results <- c(p_results, res_summary$p_results)
  
  d_out <- if (length(d_results) > 0) do.call(rbind, d_results) else NULL
  p_out <- if (length(p_results) > 0) do.call(rbind, p_results) else NULL
  
  if (!is.null(d_out)) {
    d_out <- d_out[order(!d_out$match_all,
                         !d_out$match_est,
                         !d_out$match_ci_lower,
                         !d_out$match_ci_upper), ]
  }
  
  reproduced_out <- {
    # ---- Summaries of multiverse d-values -------------------------------------
    d_summary <- if (!is.null(d_out) && nrow(d_out) > 0 &&
                     "d_rounded" %in% names(d_out)) {
      d_out |>
        dplyr::summarise(
          min_d_rounded = min(d_rounded, na.rm = TRUE),
          max_d_rounded = max(d_rounded, na.rm = TRUE)
        )
    } else {
      tibble::tibble(
        min_d_rounded = NA_real_,
        max_d_rounded = NA_real_
      )
    }
    
    # ---- Summaries of multiverse p-values -------------------------------------
    p_summary <- if (!is.null(p_out) && nrow(p_out) > 0 &&
                     "p_unrounded" %in% names(p_out)) {
      p_out |>
        dplyr::summarise(
          min_p_unrounded = min(p_unrounded, na.rm = TRUE),
          max_p_unrounded = max(p_unrounded, na.rm = TRUE)
        )
    } else {
      tibble::tibble(
        min_p_unrounded = NA_real_,
        max_p_unrounded = NA_real_
      )
    }
    
    # ---- Reported values (may be NULL) ----------------------------------------
    reported_d <- if (exists("d") && !is.null(d)) d else NA_real_
    reported_p <- if (exists("p") && !is.null(p)) p else NA_real_
    
    combined <- dplyr::bind_cols(
      d_summary,
      p_summary,
      tibble::tibble(d = reported_d, p = reported_p)
    )
    
    # ---- Logical checks (NULL-safe) -------------------------------------------
    combined <- combined |>
      dplyr::mutate(
        d_inbounds = ifelse(
          is.na(d),
          NA,
          dplyr::between(d, min_d_rounded, max_d_rounded)
        ),
        p_inbounds = ifelse(
          is.na(p),
          NA,
          dplyr::between(p, min_p_unrounded, max_p_unrounded)
        )
      )
    
    combined |>
      dplyr::mutate(d = d,
                    p = p) |>
      dplyr::select(
        d, min_d_rounded, max_d_rounded, d_inbounds,
        p, min_p_unrounded, max_p_unrounded, p_inbounds
      )
  }
  
  list(
    reproduced = reproduced_out,
    d_results  = d_out,
    p_results  = p_out
  )
}

# --- Internal Helper Functions ---

#' @keywords internal
.adjust_value <- function(x, step, code) {
  if (step == 0) return(x)
  if (code == "minus") return(x - step)
  if (code == "plus")  return(x + step)
  x  # "reported"
}

#' @keywords internal
.nct_ci <- function(t_obs, df, alpha = 0.05, max_ncp = 1000) {
  suppress_nct_warning <- function(expr) {
    withCallingHandlers(
      expr,
      warning = function(w) {
        if (grepl("full precision may not have been achieved in 'pnt\\{final\\}'",
                  conditionMessage(w))) {
          invokeRestart("muffleWarning")
        }
      }
    )
  }
  
  fL <- function(delta) suppress_nct_warning(pt(t_obs, df = df, ncp = delta) - alpha / 2)
  fU <- function(delta) suppress_nct_warning(pt(t_obs, df = df, ncp = delta, lower.tail = FALSE) - alpha / 2)
  
  lower <- -max_ncp
  upper <- max_ncp
  
  fL_low <- fL(lower)
  fL_high <- fL(upper)
  if (is.na(fL_low) || is.na(fL_high) || fL_low * fL_high > 0) {
    delta_L <- NA_real_
  } else {
    delta_L <- tryCatch(uniroot(fL, lower = lower, upper = upper)$root, error = function(e) NA_real_)
  }
  
  fU_low_check <- fU(upper)
  fU_high_check <- fU(lower)
  if (is.na(fU_low_check) || is.na(fU_high_check) || fU_low_check * fU_high_check > 0) {
    fU_low_rev <- fU(lower)
    fU_high_rev <- fU(upper)
    if (is.na(fU_low_rev) || is.na(fU_high_rev) || fU_low_rev * fU_high_rev > 0) {
      delta_U <- NA_real_
    } else {
      delta_U <- tryCatch(uniroot(fU, lower = lower, upper = upper)$root, error = function(e) NA_real_)
    }
  } else {
    delta_U <- tryCatch(uniroot(fU, lower = lower, upper = upper)$root, error = function(e) NA_real_)
  }
  
  c(delta_L, delta_U)
}

#' @keywords internal
.multiverse_validate_and_setup_summary <- function(
    ci_methods, p_methods, output_rounding,
    m1, m2, sd1, sd2, n1, n2
) {
  allowed_ci_methods      <- c("wald_t", "welch_t", "nct")
  allowed_p_methods       <- c("student_t", "welch_t")
  allowed_output_rounding <- c("half_up", "half_down", "bankers", "trunc")
  
  check_methods <- function(input, allowed, name) {
    if (!is.null(input)) {
      bad <- setdiff(input, allowed)
      if (length(bad) > 0L) {
        stop(
          name, " contains invalid values: ",
          paste0(bad, collapse = ", "),
          "\nAllowed: ", paste0(allowed, collapse = ", ")
        )
      }
      return(input)
    }
    allowed
  }
  
  ci_methods      <- check_methods(ci_methods,      allowed_ci_methods,      "ci_methods")
  p_methods       <- check_methods(p_methods,       allowed_p_methods,       "p_methods")
  output_rounding <- check_methods(output_rounding, allowed_output_rounding, "output_rounding")
  
  vals_summary <- list(m1, m2, sd1, sd2, n1, n2)
  have_summary <- all(vapply(
    vals_summary,
    function(z) !is.null(z) && length(z) > 0 && !is.na(z[1L]),
    logical(1)
  ))
  
  if (!have_summary) {
    stop("Provide M/SD/N: m1, m2, sd1, sd2, n1, n2.")
  }
  
  list(
    ci_methods      = ci_methods,
    p_methods       = p_methods,
    output_rounding = output_rounding
  )
}

#' @keywords internal
.get_digits <- function(x) {
  if (is.null(x) || length(x) == 0 || is.na(x)) return(0L)
  sx <- sub("^-", "", as.character(x[1L]))
  if (!grepl("\\.", sx)) return(0L)
  nchar(sub("^[^.]*\\.", "", sx))
}

#' @keywords internal
.multiverse_from_summary_stats <- function(
    m1, m2, sd1, sd2, n1, n2,
    ci_methods, p_methods, output_rounding,
    d_digits, p_digits, m_digits, sd_digits, alpha,
    d_num, d_ci_lower_num, d_ci_upper_num, p_num,
    idx_d, idx_p,
    direction = c("m1_minus_m2", "m2_minus_m1", "both"),
    include_se_sd_confusion = FALSE
) {
  d_results <- list()
  p_results <- list()
  
  direction <- match.arg(direction)
  dir_modes <- if (direction == "both") c("m1_minus_m2", "m2_minus_m1") else direction
  
  # Step sizes (based on user-specified digits)
  step_m1  <- 0.5 * 10^(-m_digits)
  step_m2  <- 0.5 * 10^(-m_digits)
  step_sd1 <- 0.5 * 10^(-sd_digits)
  step_sd2 <- 0.5 * 10^(-sd_digits)
  
  adj_codes <- c("reported", "minus", "plus")
  
  sd_modes  <- c("sd")
  if (isTRUE(include_se_sd_confusion)) {
    sd_modes <- c(sd_modes, "se_converted")
  }
  
  for (adj_stats in adj_codes) {
    
    # Adjust reported inputs by +/- ULP
    m1_star  <- .adjust_value(m1,  step_m1,  adj_stats)
    m2_star  <- .adjust_value(m2,  step_m2,  adj_stats)
    sd1_star <- .adjust_value(sd1, step_sd1, adj_stats)
    sd2_star <- .adjust_value(sd2, step_sd2, adj_stats)
    
    for (sd_mode in sd_modes) {
      
      if (sd_mode == "sd") {
        sd1_eff <- sd1_star
        sd2_eff <- sd2_star
      } else { # "se_converted": treat reported SDs as SEs, convert via sqrt(n)
        sd1_eff <- sd1_star * sqrt(n1)
        sd2_eff <- sd2_star * sqrt(n2)
      }
      
      if (sd1_eff <= 0 || sd2_eff <= 0) next
      
      df_s <- n1 + n2 - 2
      N    <- n1 + n2
      
      # Pooled SD
      sp <- sqrt(((n1 - 1) * sd1_eff^2 + (n2 - 1) * sd2_eff^2) / df_s)
      if (!is.finite(sp) || sp <= 0) next
      
      var1 <- sd1_eff^2
      var2 <- sd2_eff^2
      se_welch_base <- sqrt(var1 / n1 + var2 / n2)
      
      num_w <- (var1 / n1 + var2 / n2)^2
      den_w <- (var1^2 / (n1^2 * (n1 - 1))) + (var2^2 / (n2^2 * (n2 - 1)))
      df_w <- num_w / den_w
      if (!is.finite(df_w) || df_w <= 0) df_w <- NA_real_
      
      # ----------------------------------------------------------
      # Loop over direction modes
      # ----------------------------------------------------------
      for (dir_mode in dir_modes) {
        
        sign_factor     <- if (dir_mode == "m1_minus_m2") 1 else -1
        direction_label <- dir_mode
        
        diff_mean <- sign_factor * (m1_star - m2_star)
        
        # t statistics
        t_pooled <- diff_mean / (sp * sqrt(1 / n1 + 1 / n2))
        t_welch  <- diff_mean / se_welch_base
        
        # Effect sizes
        d_raw <- diff_mean / sp
        J_s   <- 1 - 3 / (4 * df_s - 1)
        g_raw <- J_s * d_raw
        
        # ----------------------------------------------------------
        # Effect sizes + CIs
        # ----------------------------------------------------------
        for (es_type in c("d", "g")) {
          
          es <- if (es_type == "d") d_raw else g_raw
          
          se_pooled <- sqrt(N / (n1 * n2) + es^2 / (2 * df_s))
          se_welch  <- if (!is.na(df_w)) sqrt(N / (n1 * n2) + es^2 / (2 * df_w)) else NA_real_
          
          for (ci_method in ci_methods) {
            
            if (ci_method == "nct") {
              delta_ci <- .nct_ci(t_pooled, df_s, alpha = alpha)
              if (any(is.na(delta_ci))) next
              
              fac_d   <- sqrt(1 / n1 + 1 / n2)
              dL_raw  <- delta_ci[1] * fac_d
              dU_raw  <- delta_ci[2] * fac_d
              
              ci_lower <- if (es_type == "d") dL_raw else J_s * dL_raw
              ci_upper <- if (es_type == "d") dU_raw else J_s * dU_raw
              
            } else { # wald_t, welch_t
              if (ci_method == "wald_t") {
                se_use   <- se_pooled
                df_for_t <- df_s
              } else { # welch_t
                se_use   <- if (!is.na(se_welch)) se_welch else se_pooled
                df_for_t <- if (!is.na(df_w)) df_w else df_s
              }
              
              crit <- qt(1 - alpha / 2, df = df_for_t)
              
              ci_lower <- es - crit * se_use
              ci_upper <- es + crit * se_use
            }
            
            # Rounding of effect sizes
            for (d_rounding in output_rounding) {
              
              d_round_fun <- switch(
                d_rounding,
                "half_up"   = function(x) roundwork::round_up(x,   d_digits),
                "half_down" = function(x) roundwork::round_down(x, d_digits),
                "bankers"   = function(x) round(x, d_digits),
                "trunc"     = function(x) roundwork::round_trunc(x, d_digits),
                stop("Unknown output_rounding option")
              )
              
              est_d   <- d_round_fun(es)
              lower_d <- d_round_fun(ci_lower)
              upper_d <- d_round_fun(ci_upper)
              
              d_results[[idx_d]] <- data.frame(
                source              = "summary",
                direction           = direction_label,
                es_type             = es_type,
                ci_method           = ci_method,
                d_rounding          = d_rounding,
                input_adj_stats     = adj_stats,
                sd_interpretation   = sd_mode,
                m1_used             = m1_star,
                m2_used             = m2_star,
                sd1_used            = sd1_eff,
                sd2_used            = sd2_eff,
                t_used              = t_pooled,
                df_used             = df_s,
                d_unrounded         = es,
                ci_lower_unrounded  = ci_lower,
                ci_upper_unrounded  = ci_upper,
                d_rounded           = est_d,
                ci_lower_rounded    = lower_d,
                ci_upper_rounded    = upper_d,
                match_est      = if (!is.na(d_num))          isTRUE(all.equal(est_d,   d_num))          else NA,
                match_ci_lower = if (!is.na(d_ci_lower_num)) isTRUE(all.equal(lower_d, d_ci_lower_num)) else NA,
                match_ci_upper = if (!is.na(d_ci_upper_num)) isTRUE(all.equal(upper_d, d_ci_upper_num)) else NA,
                match_all      = if (!any(is.na(c(d_num, d_ci_lower_num, d_ci_upper_num)))) {
                  est_d   == d_num &&
                    lower_d == d_ci_lower_num &&
                    upper_d == d_ci_upper_num
                } else NA,
                stringsAsFactors    = FALSE
              )
              
              idx_d <- idx_d + 1
            }
          }
        }
        
        # ----------------------------------------------------------
        # p-values (t-based only)
        # ----------------------------------------------------------
        for (p_method in p_methods) {
          
          t_use <- switch(
            p_method,
            "student_t" = t_pooled,
            "welch_t"   = t_welch,
            NA_real_
          )
          
          df_use <- switch(
            p_method,
            "student_t" = df_s,
            "welch_t"   = df_w,
            NA_real_
          )
          
          if (is.na(t_use) || is.na(df_use)) next
          
          p_unr <- 2 * (1 - pt(abs(t_use), df = df_use))
          
          for (p_rounding in output_rounding) {
            
            p_round_fun <- switch(
              p_rounding,
              "half_up"   = function(x) roundwork::round_up(x,   p_digits),
              "half_down" = function(x) roundwork::round_down(x, p_digits),
              "bankers"   = function(x) round(x, p_digits),
              "trunc"     = function(x) roundwork::round_trunc(x, p_digits),
              stop("Unknown output_rounding option")
            )
            
            p_rounded <- p_round_fun(p_unr)
            
            p_results[[idx_p]] <- data.frame(
              source            = "summary",
              direction         = direction_label,
              p_method          = p_method,
              p_rounding        = p_rounding,
              input_adj_stats   = adj_stats,
              sd_interpretation = sd_mode,
              t_used            = t_use,
              df_used           = df_use,
              p_unrounded       = p_unr,
              p_rounded         = p_rounded,
              match_p           = if (!is.na(p_num)) isTRUE(all.equal(p_rounded, p_num)) else NA,
              stringsAsFactors  = FALSE
            )
            
            idx_p <- idx_p + 1
          }
        }
      } # end loop over dir_modes
    }
  }
  
  list(d_results = d_results, p_results = p_results, idx_d = idx_d, idx_p = idx_p)
}

#' Plot multiverse of Cohen's d results from independent_t_test_summary
#'
#' @param res A list returned by independent_t_test_summary(),
#'   containing an element `d_results` with columns:
#'   `d_rounded`, `ci_lower_rounded`, and `ci_upper_rounded`.
#'
#' @return A ggplot object visualizing the range of recalculated rounded
#'   Cohen's d and its 95% confidence intervals across all analytic choices.
#'
#' @examples
#' plot_multiverse_d(res)
#'
#' @export
plot_multiverse_d <- function(res) {
  if (is.null(res$d_results) || nrow(res$d_results) == 0) {
    stop("`res` must include a non-empty `d_results` data frame.")
  }
  
  res_d <- res$d_results |>
    tibble::as_tibble() |>
    dplyr::arrange(.data$d_rounded) |>
    tibble::rownames_to_column(var = "rowname") |>
    dplyr::mutate(rowname = as.numeric(.data$rowname))
  
  # Define shaded regions based on range of CI limits and point estimates
  xmin_shade  <- min(res_d$ci_lower_rounded, na.rm = TRUE)
  xmax_shade  <- max(res_d$ci_upper_rounded, na.rm = TRUE)
  xmin_shade2 <- min(res_d$d_rounded, na.rm = TRUE)
  xmax_shade2 <- max(res_d$d_rounded, na.rm = TRUE)
  
  # Construct the plot
  ggplot2::ggplot(
    res_d,
    ggplot2::aes(
      y = .data$rowname,
      x = .data$d_rounded,
      xmin = .data$ci_lower_rounded,
      xmax = .data$ci_upper_rounded
    )
  ) +
    ggplot2::annotate(
      "rect",
      xmin = xmin_shade,
      xmax = xmax_shade,
      ymin = -Inf,
      ymax = Inf,
      alpha = 0.3
    ) +
    ggplot2::annotate(
      "rect",
      xmin = xmin_shade2,
      xmax = xmax_shade2,
      ymin = -Inf,
      ymax = Inf,
      alpha = 0.4
    ) +
    ggstance::geom_linerangeh() +
    ggplot2::geom_point() +
    ggplot2::theme_linedraw() +
    ggplot2::scale_x_continuous(
      name = "Recalculated rounded Cohen's d and 95% CIs",
      breaks = scales::breaks_pretty(n = 8),
      expand = ggplot2::expansion(mult = c(0.1, 0.1))
    ) +
    ggplot2::scale_y_continuous(
      labels = NULL,
      name = "Set of analytic choices"
    ) +
    ggplot2::ggtitle("Multiverse of Cohen's d and its 95% CIs")
}

#' Plot multiverse of p-values from independent_t_test_summary
#'
#' @param res A list returned by independent_t_test_summary(),
#'   containing an element `p_results` with column `p_unrounded`.
#'
#' @return A ggplot object visualizing the distribution of recalculated
#'   unrounded p-values across all analytic choices.
#'
#' @examples
#' plot_multiverse_p(res)
#'
#' @export
plot_multiverse_p <- function(res) {
  if (is.null(res$p_results) || nrow(res$p_results) == 0) {
    stop("`res` must include a non-empty `p_results` data frame.")
  }
  
  res_p <- res$p_results |>
    tibble::as_tibble() |>
    dplyr::arrange(.data$p_unrounded) |>
    tibble::rownames_to_column(var = "rowname") |>
    dplyr::mutate(rowname = as.numeric(.data$rowname))
  
  # Shaded region showing full range of p-values
  xmin_shade <- min(res_p$p_unrounded, na.rm = TRUE)
  xmax_shade <- max(res_p$p_unrounded, na.rm = TRUE)
  
  # Build the plot
  ggplot2::ggplot(
    res_p,
    ggplot2::aes(
      y = .data$rowname,
      x = .data$p_unrounded
    )
  ) +
    ggplot2::annotate(
      "rect",
      xmin = xmin_shade,
      xmax = xmax_shade,
      ymin = -Inf,
      ymax = Inf,
      alpha = 0.4
    ) +
    ggplot2::geom_point() +
    ggplot2::theme_linedraw() +
    ggplot2::scale_x_continuous(
      name = "Recalculated unrounded p-value",
      breaks = scales::breaks_pretty(n = 8),
      expand = ggplot2::expansion(mult = c(0.1, 0.1))
    ) +
    ggplot2::scale_y_continuous(
      labels = NULL,
      name = "Set of analytic choices"
    ) +
    ggplot2::ggtitle("Multiverse of p-values")
}